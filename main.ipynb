{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8765b502-bdc6-4dbb-b376-d8e9ad8e9010",
   "metadata": {},
   "source": [
    "## Packages and Functions Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ab53a64-5d4f-4d6e-be25-9e4a118a97b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import numpy as np\n",
    "import tdmclient.notebook\n",
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "from CV_function import *\n",
    "from path_object import *\n",
    "from Markov_Filter import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eb92d0",
   "metadata": {},
   "source": [
    "## Thymio Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec54474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters \n",
    "WALL_THRESHOLD = 500\n",
    "ROBOT_SPEED = 150\n",
    "CM_SEC = 6 # 6 cm per second at motor speed 150 used for driving straigt\n",
    "SEC_REVOLUTION = 9 # 9 seconds for 360 degrees at motor speed 100 used for turning\n",
    "\n",
    "#Initialize robot\n",
    "try:\n",
    "    await tdmclient.notebook.stop()\n",
    "except:\n",
    "    pass\n",
    "await tdmclient.notebook.start()\n",
    "\n",
    "#function to sync variables between the notebook and the robot\n",
    "@tdmclient.notebook.sync_var\n",
    "def get_prox():\n",
    "    global prox_horizontal\n",
    "    return prox_horizontal\n",
    "\n",
    "def local_navigation():\n",
    "    global WALL_THRESHOLD, ROBOT_SPEED\n",
    "    max_allowed_speed = 150\n",
    "    set_var(leds_top = [32, 0, 0])\n",
    "    while max(get_prox())>WALL_THRESHOLD:\n",
    "        weight_left = [25,  15, -20, -15, -25]\n",
    "        weight_right = [-25, -15, -15,  15,  25]\n",
    "    \n",
    "        # Scale factors for sensors and constant factor\n",
    "        sensor_scale = 500\n",
    "    \n",
    "        mem_sensor = [0,0,0,0,0]\n",
    "        prox_horizontal = get_prox()\n",
    "        \n",
    "        for i in range(len(mem_sensor)):\n",
    "            # Get and scale inputs\n",
    "            mem_sensor[i] = prox_horizontal[i] // sensor_scale\n",
    "    \n",
    "        y = [ROBOT_SPEED,ROBOT_SPEED]   \n",
    "        \n",
    "        for i in range(len(mem_sensor)):   \n",
    "            # Compute outputs of neurons and set motor powers\n",
    "            y[0] = y[0] + mem_sensor[i] * weight_left[i]\n",
    "            y[1] = y[1] + mem_sensor[i] * weight_right[i]\n",
    "    \n",
    "        # Set motor powers\n",
    "        set_var(motor_left_target = min(y[0],max_allowed_speed))\n",
    "        set_var(motor_right_target = min(y[1],max_allowed_speed))\n",
    "        time.sleep(0.2)\n",
    "    set_var(leds_top = [0, 0, 32])\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "@tdmclient.notebook.sync_var\n",
    "# drive straight with \"speed\" (motor speed)\n",
    "def motors_drive(l_speed=500, r_speed=500):\n",
    "    global motor_left_target, motor_right_target\n",
    "    \n",
    "    motor_left_target = l_speed\n",
    "    motor_right_target = r_speed\n",
    "\n",
    "# drive \"dist\" [cm]\n",
    "def drive(dist=10):\n",
    "    global WALL_THRESHOLD, ROBOT_SPEED, CM_SEC\n",
    "    motors_drive(ROBOT_SPEED,ROBOT_SPEED) #test with lower speed value\n",
    "    for i in range(20):\n",
    "        time.sleep((dist/(CM_SEC))/20) #motor speed = 150 equals 6cm/s -> calculates how many s you have to drive to cover a distance \"dist\" [cm]\n",
    "        if max(get_prox()) > WALL_THRESHOLD:\n",
    "            print(\"obstacle detected\")\n",
    "            local_navigation()\n",
    "            break\n",
    "    motors_drive(0,0)\n",
    "\n",
    "\n",
    "@tdmclient.notebook.sync_var \n",
    "# turn in a circle with \"speed\" (motor speed)\n",
    "def motors_turn(speed=100):\n",
    "    global motor_left_target, motor_right_target\n",
    "    motor_left_target = -speed\n",
    "    motor_right_target = speed\n",
    "    \n",
    "@tdmclient.notebook.sync_var \n",
    "def motors_turn_right(speed=100):\n",
    "    global motor_left_target, motor_right_target\n",
    "    motor_left_target = speed\n",
    "    motor_right_target = -speed\n",
    "\n",
    "# turn \"angle\" [degrees] anticlockwise\n",
    "def turn_degrees(angle):\n",
    "    global SEC_REVOLUTION\n",
    "    if angle < 0:\n",
    "        motors_turn()\n",
    "        time.sleep(abs(angle)*SEC_REVOLUTION/360) # 9s for 360Â° turn with motor speed = 100\n",
    "        motors_turn(speed=0)\n",
    "    else:\n",
    "        motors_turn_right()\n",
    "        time.sleep(abs(angle)*SEC_REVOLUTION/360)\n",
    "        motors_turn_right(speed=0)\n",
    "\n",
    "# turn \"angle\" (2. row of Astar_moves) then drive \"dist\" (1.row of Astar_moves)\n",
    "def follow_path(dist,angle):\n",
    "    turn_degrees(angle)\n",
    "    drive(dist)\n",
    "    \n",
    "#used to initialize the follow robot command\n",
    "def follow_path_init(path, current_angle,scale_factor):\n",
    "    Ang = get_angle(path[0],path[1])\n",
    "    Ang = Ang  - current_angle\n",
    "    if abs(Ang) > 180:\n",
    "                    if Ang > 0:\n",
    "                        Ang = Ang-360\n",
    "                    else:\n",
    "                        Ang = Ang+360\n",
    "    dist = get_distance(path[0],path[1])\n",
    "    current_angle = Ang + current_angle\n",
    "    follow_path(dist*scale_factor,-Ang)\n",
    "    return current_angle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ac688e-cae4-499b-911a-582222ad1022",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f164c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "map_max_x = 100\n",
    "map_max_y = 75\n",
    "#Initialize Global path object\n",
    "global_nav = Global_nav()\n",
    "#initialize markov filter map \n",
    "initialize_maps(map_max_x,map_max_y)\n",
    "\n",
    "\n",
    "#Set current angle to 0\n",
    "current_angle = 0\n",
    "#robot LED in driving mode\n",
    "set_var(leds_top = [0, 0, 32])\n",
    "\n",
    "i = 0\n",
    "#Initialize camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID') \n",
    "output_ = cv2.VideoWriter('output.avi', fourcc, frames_per_second, (frame_height, frame_width)) \n",
    "while cap.isOpened():\n",
    "    \n",
    "    #image localization\n",
    "    success, frame = cap.read()\n",
    "    if  success:\n",
    "        ## Computer vision detection\n",
    "        array_box_dim_tot, annotated_frame = detection(frame)\n",
    "        \n",
    "        sorted_object = sorted(array_box_dim_tot, key=lambda x: order.get(x[0]))\n",
    "        #break when q is pressed\n",
    "        key = cv2.waitKey(1) & 0xFF \n",
    "        if key == ord('c'):  \n",
    "            break  \n",
    "    else:\n",
    "        print(\"Unable to load the camera pic\")\n",
    "        break\n",
    "\n",
    "    #fixing output from camera, use last output if no object is detected\n",
    "    sorted_object = fix_output(sorted_object,sorted_object_last)\n",
    "    \n",
    "\n",
    "    #blind mode if no object is detected. Follow last calculated path with position and angle update from robot itself\n",
    "    if sorted_object == False: \n",
    "        start = opti_path[1] \n",
    "        opti_path = opti_path[1:]\n",
    "        if len(opti_path) == 1:\n",
    "            print(\"Reached goal\")\n",
    "            set_var(leds_top = [0, 32, 0])\n",
    "            break\n",
    "        current_angle = follow_path_init(opti_path,current_angle,scale_factor)\n",
    "        last_robot_pos = list(start)\n",
    "        #print frame\n",
    "        annotated_frame = frame\n",
    "        cv2.imshow(\"frame\", annotated_frame)\n",
    "        continue #skip rest of loop to try to find object in next frame\n",
    "\n",
    "    #save last output\n",
    "    sorted_object_last = sorted_object\n",
    "\n",
    "    #change format of pic output \n",
    "    start, goal, earth, robot_radius, earth_radius, black_holes_centers, black_holes_radiuss,scale_factor = global_nav.convert_OPENCV_tovalues(sorted_object)\n",
    "    #if distance between robot and mars is less than 5 stop \n",
    "    if get_distance(start,goal) < 4:\n",
    "        print(\"Reached goal\")\n",
    "        set_var(leds_top = [0, 32, 0])\n",
    "        break\n",
    "    \n",
    "    #create map for gloabl navigation\n",
    "    occ, _,_=  global_nav.create_map( goal = goal ,black_holes_centers = black_holes_centers,black_holes_radiuss=black_holes_radiuss)\n",
    "\n",
    "    #use markov filter to update position \n",
    "    if i>0:\n",
    "        start = markov(opti_path[1][0],opti_path[1][1],start[0],start[1],sorted_object[0][2],i==0)        \n",
    "\n",
    "    #return path. Use the opti_path! \n",
    "    opti_path, _, _, _ = global_nav.get_path_straight(start=start,goal=goal)\n",
    "\n",
    "    #convert optipath to format used by camera\n",
    "    scaled_coords = convert_coordinates_2d_list(opti_path)\n",
    "\n",
    "    #annotate frame\n",
    "    if i>0:\n",
    "        annotation(annotated_frame, scaled_coords)\n",
    "    cv2.imshow(\"frame\", annotated_frame)\n",
    "    output_.write(annotated_frame)\n",
    "    \n",
    "    #update current angle. Take the average of the calculated from image and robot motion\n",
    "    if i != 0: \n",
    "        if list(start) != last_robot_pos:\n",
    "            current_angle = update_angle(last_robot_pos,start,current_angle)\n",
    "\n",
    "\n",
    "    #follow first two points in path\n",
    "    current_angle = follow_path_init(opti_path,current_angle,scale_factor)\n",
    "\n",
    "    #save last robot position\n",
    "    last_robot_pos = list(start)\n",
    "\n",
    "    i+=1\n",
    "\n",
    "#print last frame and save video\n",
    "success, frame = cap.read()\n",
    "array_box_dim_tot, annotated_frame = detection(frame)\n",
    "cv2.imshow(\"frame\", annotated_frame)\n",
    "cv2.startWindowThread()\n",
    "cap.release()\n",
    "output_.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14880223-fdcb-415c-8caa-7fb228495b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
